{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9z7JPxpORS9Y+B02qeuuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kargin-Alexey/study_projects/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "## Введение\n",
        "MNIST (сокращение от «Modified National Institute of Standards and Technology») — объёмная база данных образцов рукописного написания цифр. База данных является стандартом, предложенным Национальным институтом стандартов и технологий США с целью калибрации и сопоставления методов распознавания изображений с помощью машинного обучения.    \n",
        "\n",
        "База данных была создана после переработки оригинального набора чёрно-белых образцов размером 20x20 пикселей NIST. Создатели базы данных NIST, в свою очередь, использовали набор образцов из Бюро переписи населения США, к которому были добавлены ещё тестовые образцы, написанные студентами американских университетов. Образцы из набора NIST были нормализированы, прошли сглаживание и приведены к серому полутоновому изображению размером 28x28 пикселей.\n",
        "\n",
        "База данных MNIST содержит 60000 изображений для обучения и 10000 изображений для тестирования.\n",
        "\n",
        "Производились многочисленные попытки достичь минимальной ошибки после обучения по базе данных MNIST, которые обсуждались в научной литературе. Рекордные результаты указывались в публикациях, посвящённых использованию свёрточных нейронных сетей, уровень ошибки был доведён до 0,23 %. Сами создатели базы данных предусмотрели несколько методов тестирования. В оригинальной работе указывается, что использование метода опорных векторов позволяет достичь уровня ошибки 0,8 %.\n",
        "\n",
        "__Цель:__ Поэкспериментировать классифицировать озображения с помощью различных алгоритмов МО. Попробовать улучшить качество классификации с помощью обработки изображений."
      ],
      "metadata": {
        "id": "JLKoAIcgOhmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выгрузка данных\n",
        "Сделаем ипорт библиотек и данных. Данные будут взяты из билиотеки scikit-learn"
      ],
      "metadata": {
        "id": "CP_ZuMD-Quay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9-LMyXagOew9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')"
      ],
      "metadata": {
        "id": "YoIvg87fUEnd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X, y = np.array(mnist[\"data\"]), np.array(mnist[\"target\"])"
      ],
      "metadata": {
        "id": "UexH-QTmR-Ie"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KyAvPGtS4Nh",
        "outputId": "2fa955a3-bb3c-4ce2-ac18-5b001baacab3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_cQlL6uT4pI",
        "outputId": "d3daf7a1-7e24-4577-bdde-2ae942f9f93e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000,)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, как выглядят изображения. Сформулруем гипотезы для возможного улучшения будущих моделей."
      ],
      "metadata": {
        "id": "IPJYSaLmUzl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = X[:4]\n",
        "img = img.reshape(4,28,28)\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15,6))\n",
        "for i in range(4):\n",
        "  axs[i].imshow(img[i], cmap='binary',interpolation='nearest')\n",
        "  axs[i].axis(\"off\")\n",
        "\n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "tN6m6f6ZUyvt",
        "outputId": "d58b9401-b359-4095-ad83-fb32f1d58e3b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На изображениях цифры `5, 0, 4, 1`. Сразу можно сказать, что у изображений можно нормализовать значение яркости пикселя, делать более четкие контуры, убирать лишнее пространство. По цифре `5` видно, что алгоритмы могут легко путать некоторые цифры, потому что они написаны от руки и даже человек не всегда сможет всё правильно классифицировать. \n",
        "\n",
        "Разобьём набор на тестовый и тренировочный. MNIST уже разделен на тренировочный и тестовый набор, как сказано выше. Дополнительно перемешаем тестовый набор данных "
      ],
      "metadata": {
        "id": "eX4puyUhXIC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "shuffle_index = np.random.permutation(60000)\n",
        "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n"
      ],
      "metadata": {
        "id": "FmVFF2w-T91Y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бинарная классификация\n",
        "\n",
        "Попробуем реализовать бинарную классификацию классическими алгоритмами, чтобы получить базовое качество для будущих моделей. \n",
        "\n",
        "Для начала обычим классификатор выявлять `5`. В качестве классификатора SGD, так как он хорошо справляется с большими объёмами данных."
      ],
      "metadata": {
        "id": "TFQ5dn8Y3sE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_5 = (y_train =='5')\n",
        "y_test_5 = (y_test =='5')"
      ],
      "metadata": {
        "id": "Gb9JRyuE7FO4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTZkfsFN2G7_",
        "outputId": "7b334051-c1cb-45fd-d95d-53df216594e3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируем на изображениях, которые мы выводили."
      ],
      "metadata": {
        "id": "ySPMiIJL84hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf.predict(img.reshape(4,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqPhfIea7nQ1",
        "outputId": "07efdb2d-b17a-47f8-c467-9e437a1e5d06"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На изветсных нам изображзениях классификатор дал верный ответ. Оценим его качество на тренировочной выборке с помощью перекрестной проверки."
      ],
      "metadata": {
        "id": "zKehgVUJ9eHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_5.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEwwU382_Ljf",
        "outputId": "27e515bb-486d-4014-d79a-baa6bbf0f9e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09035"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJXUT5Vl9bH_",
        "outputId": "d67b5f11-bc00-44ac-da98-37c96871bacc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9638 , 0.94975, 0.96095])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество более 93%. Из-за того, что выборка сильно несбалансированна, всего около 9% пятёрок, метрика `accuracy` не подходит для адекватной оценки качества.\n",
        "Лучше себя покажут метрики `'roc_auc','f1','precision','recall'`, помотрим на их разброс в зависимости от  "
      ],
      "metadata": {
        "id": "gwtGkdOd_T8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['roc_auc','f1','precision','recall']\n",
        "cross_validate(sgd_clf, X_train, y_train_5, cv=3, scoring=scoring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbn8I3v2_OC6",
        "outputId": "c7122ab6-dca6-4767-a994-9fa77a3d54ad"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([7.23324728, 7.10214472, 9.58516979]),\n",
              " 'score_time': array([0.07021141, 0.06527758, 0.06506228]),\n",
              " 'test_f1': array([0.76401565, 0.6203249 , 0.7951744 ]),\n",
              " 'test_precision': array([0.92942109, 0.97738095, 0.7557328 ]),\n",
              " 'test_recall': array([0.64858882, 0.45434422, 0.8389596 ]),\n",
              " 'test_roc_auc': array([0.96976856, 0.95932918, 0.96994846])}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`roc_auc` достаточно стабильно показывает качество в райне 96-97%, значение метрики `f1` сильно колеблется, в зависимости от набора данных, что не позволяет стабильно адекватно оценивать качество модели.\n",
        "Проверим качество этой модели на тестовой выборке."
      ],
      "metadata": {
        "id": "BdYZZdsMDT-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test_5, sgd_clf.predict(X_test), average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ldWAyM_J4S",
        "outputId": "231d6664-1977-40a1-fe34-6eec9a75764f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8899324203233347"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Базовое `roc_auc` возьмём за 0.87. Проверим, какое качество покажет модель RandomForestClassifier"
      ],
      "metadata": {
        "id": "HGTBuqsyGyQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "forest_clf.fit(X_train, y_train_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Npzl60Gxg7",
        "outputId": "7184e430-8b29-4ec7-c917-e0274b8bb68e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test_5, forest_clf.predict(X_test), average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3X2l1-tH275",
        "outputId": "fb9bbe49-7adb-42dd-b121-a8b0f9b19cea"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369452469715679"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество модели случайного леса значительно отличает от стохастического градиента. Попробуем ещё поднять качество этих алгоритмов, нормализовав данные на максимальное значение."
      ],
      "metadata": {
        "id": "_W4O_oN-JDmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_n = (X_train /  X_train.max()).copy()\n",
        "X_test_n = (X_test /  X_train.max()).copy()"
      ],
      "metadata": {
        "id": "zdtrrNDEH7fo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_n.max(), X_test_n.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH_4OC_BJfub",
        "outputId": "79fb6bf6-8c90-46d8-f9f3-07a705c3c900"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf.fit(X_train_n, y_train_5)\n",
        "forest_clf.fit(X_train_n, y_train_5)\n",
        "print('Качество модели SGD',roc_auc_score(y_test_5, sgd_clf.predict(X_test_n), average='weighted'))\n",
        "print('Качество модели RandomForest',roc_auc_score(y_test_5, forest_clf.predict(X_test_n), average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWgvyeOXKKIX",
        "outputId": "11a83750-c236-42fb-e798-ec6ffdcd92e0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Качество модели SGD 0.9101753054034202\n",
            "Качество модели RandomForest 0.9369452469715679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ожидаемо, для линейной модели качество подросло до 0.89."
      ],
      "metadata": {
        "id": "T1pDpOgGmh9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Многоклассовая классификация\n",
        "\n",
        "Есть 3 тактики построения такой классификации:\n",
        "- Использовать классификаторы, способные разделять больш, чем 2 класса\n",
        "- Использовать бинарные классификаторы со стратегией \"один против всех\"(OvA)\n",
        "- Использовать бинарные классификаторы со стратегией \"каждый против каждого\"(OvO)\n",
        "\n",
        "sklearn автоматически определяет, что мы используем многоклассовую классификацию и использует стратегию OvA для бинарных классификаторов, кроме метода опорных векторов.    \n",
        "Применим те же алгоритм, но в случае многоклассовой классификации.\n"
      ],
      "metadata": {
        "id": "6hGFTB6QRLnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_clf_mult = SGDClassifier(random_state=42)\n",
        "sgd_clf_mult.fit(X_train, y_train.astype('int'))"
      ],
      "metadata": {
        "id": "O9DvBcwBibrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45c25e9-e963-4704-93db-d16b39cb6962"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(sgd_clf_mult.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfbNCe2VV47b",
        "outputId": "fb8b3966-c154-4449-e6df-297414a1a948"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем матрицу ошибок и определим какие цифры путаются чаще"
      ],
      "metadata": {
        "id": "A_77P8nBUJvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_m = confusion_matrix(y_test.astype('int'), sgd_clf_mult.predict(X_test))\n",
        "norm_conf_m = conf_m / conf_m.sum(axis=1, keepdims=True)\n",
        "np.fill_diagonal(norm_conf_m, 0)\n",
        "plt.matshow(norm_conf_m, cmap='gray')"
      ],
      "metadata": {
        "id": "kGKb8rx6VTIB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "15a7af64-3e45-4271-8f0e-3c7c0512dac7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4588b33290>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполнив глывную диагональ 0, мы оставили в матрице только ошибки. Видим, что SGD часто путает классифицирует `4`, как `9`, возможно из-за разных способов написания этой цифры. Также ошибки часто возникают при классификации `3` и `5`. В строке `9` много светлых квадратов, что говорит о большом количестве ложно положительных результатов. При этом сами девятки классифицировались довольно точно.   "
      ],
      "metadata": {
        "id": "RKolcHpbfvz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "WlzlMNxpy2cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим трехснолйную полносвязную нейронную сеть. Посмотрим какое качество она сможет показать на данном наборе."
      ],
      "metadata": {
        "id": "9iG8EKDiQHky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlMY6qO80B_t",
        "outputId": "fead7542-a652-4909-9ff7-3c7a6890e52a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (5): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для упрощения обучения нейронной, снова загрузим данные. Так как датасет изначально разбит на обучающий и тестовый, то все модели сравниваются в качестве на одих и тех-же данных. При выгрузке данных сформируем батчи по 32 изображения. Самиизображения нормализуем, приведя значения яркости пикселей к диапазону от -1, до 1."
      ],
      "metadata": {
        "id": "mtcR-KwnRTEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "trainset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "jkyNTbc05KyM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве метрики используем negative log likelihood loss, она хорошо подходт для решения задачь многоклассовой классификации."
      ],
      "metadata": {
        "id": "2Trzw7j0WLI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "metadata": {
        "id": "d7P9oHsD2vh1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9h8emlH24sm",
        "outputId": "0920f87e-e6b8-48bc-cdc7-5e7d51bd3a00"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
            "        [-0.0053, -0.0053, -0.0053,  ..., -0.0053, -0.0053, -0.0053],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оптимизатором в данной модели используем SGD."
      ],
      "metadata": {
        "id": "QZRkoJwFXKrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "metadata": {
        "id": "BxoDeJjA3AMy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(32, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwuofQQD4p7U",
        "outputId": "90dd35c0-36bd-4903-80fe-d40885d6ba8b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0158, -0.0222,  0.0195,  ...,  0.0345, -0.0211, -0.0293],\n",
            "        [ 0.0121, -0.0016, -0.0283,  ..., -0.0100, -0.0165, -0.0301],\n",
            "        [ 0.0162, -0.0083, -0.0186,  ..., -0.0343, -0.0272, -0.0137],\n",
            "        ...,\n",
            "        [ 0.0165, -0.0356, -0.0350,  ..., -0.0116, -0.0287, -0.0253],\n",
            "        [-0.0169, -0.0289,  0.0139,  ...,  0.0019,  0.0203, -0.0316],\n",
            "        [ 0.0309, -0.0355,  0.0010,  ..., -0.0175, -0.0200,  0.0061]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
            "        [-0.0034, -0.0034, -0.0034,  ..., -0.0034, -0.0034, -0.0034],\n",
            "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
            "        ...,\n",
            "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
            "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
            "        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO7FMCMn4s6n",
        "outputId": "c56668b2-b48f-4d9b-f02c-868ce5660117"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0158, -0.0222,  0.0195,  ...,  0.0345, -0.0211, -0.0293],\n",
            "        [ 0.0121, -0.0016, -0.0283,  ..., -0.0099, -0.0164, -0.0300],\n",
            "        [ 0.0162, -0.0083, -0.0186,  ..., -0.0343, -0.0273, -0.0137],\n",
            "        ...,\n",
            "        [ 0.0165, -0.0356, -0.0350,  ..., -0.0116, -0.0287, -0.0253],\n",
            "        [-0.0169, -0.0289,  0.0139,  ...,  0.0019,  0.0203, -0.0316],\n",
            "        [ 0.0309, -0.0355,  0.0010,  ..., -0.0176, -0.0200,  0.0061]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим обучение - 20 эпох."
      ],
      "metadata": {
        "id": "mg0w55ueX-L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "time0 = time()\n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Epoch {e} - Training loss: {running_loss/len(trainloader)}\")\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW5RgrcM4wXT",
        "outputId": "7afab013-bf2a-47b7-e388-beacbb16836e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training loss: 0.5442788770357768\n",
            "Epoch 1 - Training loss: 0.25469048287669815\n",
            "Epoch 2 - Training loss: 0.18773534723122914\n",
            "Epoch 3 - Training loss: 0.14861114405095577\n",
            "Epoch 4 - Training loss: 0.12326566871404648\n",
            "Epoch 5 - Training loss: 0.10549304984137416\n",
            "Epoch 6 - Training loss: 0.09188183048802118\n",
            "Epoch 7 - Training loss: 0.08126626476707557\n",
            "Epoch 8 - Training loss: 0.07197220706834147\n",
            "Epoch 9 - Training loss: 0.06608075941149145\n",
            "Epoch 10 - Training loss: 0.05816989509103199\n",
            "Epoch 11 - Training loss: 0.053897836486405386\n",
            "Epoch 12 - Training loss: 0.050119156069060165\n",
            "Epoch 13 - Training loss: 0.04492121666623279\n",
            "Epoch 14 - Training loss: 0.04167759813455244\n",
            "Epoch 15 - Training loss: 0.0384022954631752\n",
            "Epoch 16 - Training loss: 0.0352665314878958\n",
            "Epoch 17 - Training loss: 0.032685591064129646\n",
            "Epoch 18 - Training loss: 0.02970027137869814\n",
            "Epoch 19 - Training loss: 0.028114386502676645\n",
            "\n",
            "Training Time (in minutes) = 3.769890824953715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем в каких соотношениях модель предсказывает класс обекта."
      ],
      "metadata": {
        "id": "9rN72qEJZKEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def view_classify(img, ps):\n",
        "    ''' Фукнция, печатающая изображение и вероятности классов\n",
        "    '''\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "ZCECk59j4yzJ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.cpu().numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "U1r1bZLW42yy",
        "outputId": "6da78769-f979-485b-ea16-0732c0946e01"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Digit = 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассчитаем ошибку модели. Для простоты, используем метрику accuracy."
      ],
      "metadata": {
        "id": "eLHmZ5nnZZEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "        \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ji_Hb5O46xg",
        "outputId": "d62bd692-e55f-4921-b4e9-c5aa1afc6216"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6HQvjzk96UvV"
      },
      "execution_count": 71,
      "outputs": []
    }
  ]
}